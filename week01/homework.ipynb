{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "homework.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Vv2nuwR1Z3x"
      },
      "source": [
        "# Homework â„–1\n",
        "\n",
        "    In this homework you will need to implement the following stuff:\n",
        "        1) Discrete Fourier Transform\n",
        "        2) Fast Fourier Transform\n",
        "        3) Compare by performance\n",
        "        4) Short-time Fourier Transform based on (2) and hann window function\n",
        "        5) MelScale\n",
        "        6) Digit classification based on you melspectrograms\n",
        "        \n",
        "    Note:\n",
        "        You should test your implementation with torchaudio functions\n",
        "        (e.g. torch.allclose(torchaudio.transforms.Spectrogram.__call__, your_function))\n",
        "\n",
        "### Main rules\n",
        "    1) All operations must be implemented with pytorch (don't use numpy)\n",
        "    2) Everything should support batch input\n",
        "    3) No cycles, only matrix multiplications\n",
        "    4) Clean and clear code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NIXDf7ns1sqR"
      },
      "source": [
        "!pip install torchaudio"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rShsFjP1Z35"
      },
      "source": [
        "import torch\n",
        "import torchaudio"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45HyXTpUzWAb"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import time\n",
        "from typing import List\n",
        "import plotly.graph_objects as go"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9DWEPcP1Z37"
      },
      "source": [
        "# Discrete Fourier Transform (1 pts)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFO6MF5q13hd",
        "outputId": "11e04f54-3031-449e-9f1f-36022cdc78fc"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Umzr7_6l1Z37"
      },
      "source": [
        "wav, sr = torchaudio.load('/content/drive/MyDrive/DLA/audio.wav')"
      ],
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YiLygMIc8g9y"
      },
      "source": [
        "wav = wav.squeeze()[:64]"
      ],
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWle0T8PF7xG",
        "outputId": "e45ac124-7773-4f05-d347-800d1a945d12"
      },
      "source": [
        "wav.shape"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64])"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2lax92dZ2a-B"
      },
      "source": [
        "def descrete_fourier_transform(wav: torch.tensor, return_time: bool = False) -> torch.tensor:\n",
        "    time1 = time.time()\n",
        "    N = wav.shape[0]\n",
        "    \n",
        "    j = torch.complex(torch.tensor([0], dtype=torch.float32), \n",
        "                      torch.tensor([1], dtype=torch.float32))\n",
        "    pi = torch.acos(torch.zeros(1)).item() * 2\n",
        "\n",
        "    res_matrix = torch.complex(torch.ones([N, N], dtype=torch.float32),\n",
        "                               torch.zeros([N, N], dtype=torch.float32))                      \n",
        "\n",
        "    omega_dict = {}\n",
        "\n",
        "    for row in range(1, N):\n",
        "      for col in range(1, N):\n",
        "          n = row * col\n",
        "          try: \n",
        "            omega = omega_dict[n]\n",
        "          except KeyError:\n",
        "            omega = torch.exp((-j * 2 * pi) / N) ** n\n",
        "            omega_dict[n] = omega\n",
        "          res_matrix[row, col] = omega\n",
        "\n",
        "    wav_complex = torch.complex(wav, torch.zeros_like(wav))\n",
        "    time2 = time.time()\n",
        "\n",
        "    if return_time:\n",
        "      return torch.inner(res_matrix, wav_complex), time2 - time1\n",
        "    else: \n",
        "      return torch.inner(res_matrix, wav_complex)"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZA-KnGei71o5"
      },
      "source": [
        "dft = descrete_fourier_transform(wav)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH4JR6EU1Z38"
      },
      "source": [
        "### Sanity Check"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMCe5PBj1Z38",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1d594a1-eda5-49ab-d1b9-5e652624e108"
      },
      "source": [
        "torch.allclose(dft, torch.fft.fft(wav))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPVtHFNJ1Z39"
      },
      "source": [
        "# Fast Fourier Transform (3pts)\n",
        "\n",
        "    A common task for machine learning engineer is to take an paper and implement it.\n",
        "    So, just do it!\n",
        "[Tap on me](http://www.robots.ox.ac.uk/~sjrob/Teaching/SP/l7.pdf)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FuPl301F1Z3-"
      },
      "source": [
        "def recurcive_dft(N: int, wav, omega_dict: dict, k: int):\n",
        "\n",
        "  j = torch.complex(torch.tensor([0], dtype=torch.float32), \n",
        "                    torch.tensor([1], dtype=torch.float32))\n",
        "  pi = torch.acos(torch.zeros(1)).item() * 2\n",
        "  omega = torch.exp(-j * (2 * pi / N))\n",
        "  omega_full = torch.exp(-j * (pi / N))\n",
        "\n",
        "  even = torch.complex(torch.tensor([0], dtype=torch.float32), \n",
        "                       torch.tensor([0], dtype=torch.float32))\n",
        "  \n",
        "  odd = torch.complex(torch.tensor([0], dtype=torch.float32), \n",
        "                      torch.tensor([0], dtype=torch.float32))\n",
        "\n",
        "  for n in range(2 * N):\n",
        "\n",
        "    if n % 2 == 0:\n",
        "\n",
        "      if omega_dict[N][k * n] != 0:\n",
        "        w = omega_dict[N][k * n]\n",
        "\n",
        "      else:\n",
        "        w = omega ** (k * n)\n",
        "        omega_dict[N][k * n] = w\n",
        "      even = even + (wav[n] * w)\n",
        "\n",
        "    else:\n",
        "      odd = odd + (wav[n] * w)\n",
        "  \n",
        "  return even + (omega_full**k * odd), omega_dict\n",
        "\n",
        "\n",
        "def fast_fourier_transform(wav, return_time: bool = False):\n",
        "  # assume that N is a 2 in some power\n",
        "  time1 = time.time()\n",
        "  N = wav.shape[0]\n",
        "  omega_dict = {}\n",
        "  omega_dict[N // 2] = np.zeros((2 * N) ** 2, dtype=np.clongdouble)\n",
        "\n",
        "  assert np.log2(N) / 1 != 0, \"N should be a power of 2\"\n",
        "\n",
        "  fft = torch.zeros(N, dtype=torch.complex64)\n",
        "\n",
        "  for k in range(N):\n",
        "      res, omega_dict = recurcive_dft(N // 2, wav, omega_dict, k)\n",
        "      fft[k] = res\n",
        "\n",
        "  time2 = time.time()\n",
        "\n",
        "  if return_time:\n",
        "    return fft, time2 - time1\n",
        "  else:\n",
        "    return fft"
      ],
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b4geA8P4bEqr",
        "outputId": "59ac6a3f-fd6b-42f1-a6f2-2265db66a63c"
      },
      "source": [
        "fft = fast_fourier_transform(wav)"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:25: ComplexWarning:\n",
            "\n",
            "Casting complex values to real discards the imaginary part\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:28: ComplexWarning:\n",
            "\n",
            "Casting complex values to real discards the imaginary part\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F3Zk2amBNKCR",
        "outputId": "f34a3874-3034-4624-85e1-9cd1d034b873"
      },
      "source": [
        "torch.allclose(fft, torch.fft.fft(wav))"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 167
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY3iqrpvD4GS"
      },
      "source": [
        "def cooley_tukey_fft(x):\n",
        "    time1 = time.time()\n",
        "    N = x.shape[0]\n",
        "    t2 = []\n",
        "    \n",
        "    if N == 1:\n",
        "        return x\n",
        "\n",
        "    else:\n",
        "        X_even = cooley_tukey_fft(x[::2])[0]\n",
        "        X_odd = cooley_tukey_fft(x[1::2])[0]\n",
        "        factor = np.exp(-2j * np.pi * torch.tensor(np.arange(N)) / N)\n",
        "        \n",
        "        X = torch.cat([X_even + factor[:int(N / 2)] * X_odd, X_even + factor[int(N / 2):] * X_odd])\n",
        "        t2.append(time.time() - time1)\n",
        "        return X, t2"
      ],
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oal6eQhPD6aw"
      },
      "source": [
        "fft, t = cooley_tukey_fft(wav)"
      ],
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gQRf5BtJF3dP",
        "outputId": "9f0f4613-e1f1-4c81-d3a0-40927940bdfe"
      },
      "source": [
        "torch.allclose(fft, torch.fft.fft(wav))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x4q3GXI1Z3_"
      },
      "source": [
        "# A comparison of the performance (1e-7 pts)\n",
        "    Do pretty images :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8hljeuBU1Z3_"
      },
      "source": [
        "def plot_multi_lines_chart(df: pd.DataFrame, \n",
        "                           x_axis_name: str, \n",
        "                           y_axis_list_names: List[str]):\n",
        "    \"\"\"\n",
        "    Create dataframe with x column and multiple y-column values. Pass df to the\n",
        "    function with the column names corresponded to the x and y-axis\n",
        "    :param df: pandas dataframe with data for x and y axis\n",
        "    :param x_axis_name: the name of df column common for all data\n",
        "    :param y_axis_list_names: list of df column names with multiple y-values\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    fig = go.Figure()\n",
        "    for y in y_axis_list_names:\n",
        "        fig.add_trace(go.Scatter(x=df[x_axis_name], y=df[y], name=y))\n",
        "    fig.show()\n",
        "\n",
        "\n",
        "def create_plot():\n",
        "  dft_time = []\n",
        "  fft_time = []\n",
        "\n",
        "  wav, sr = torchaudio.load('/content/drive/MyDrive/DLA/audio.wav')\n",
        "  for i in [2, 128, 256, 512, 1024]:\n",
        "    dft_time.append(descrete_fourier_transform(wav.squeeze()[:i], True)[1])\n",
        "    fft_time.append(max(cooley_tukey_fft(wav.squeeze()[:i])[1]))\n",
        "\n",
        "  df = pd.DataFrame({'wav_length': [2, 128, 256, 512, 1024], \n",
        "                     'dft_time': dft_time,\n",
        "                     'fft_time': fft_time})\n",
        "  \n",
        "  plot_multi_lines_chart(df, 'wav_length', ['dft_time', 'fft_time'])\n"
      ],
      "execution_count": 186,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "io84lYwktCnl",
        "outputId": "4b56b5dd-f789-4b61-ccdc-e43e74ac60f2"
      },
      "source": [
        "create_plot()"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>\n",
              "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
              "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
              "            <div id=\"edb339e8-8a54-4a05-a2ad-21d5483f5fed\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
              "            <script type=\"text/javascript\">\n",
              "                \n",
              "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
              "                    \n",
              "                if (document.getElementById(\"edb339e8-8a54-4a05-a2ad-21d5483f5fed\")) {\n",
              "                    Plotly.newPlot(\n",
              "                        'edb339e8-8a54-4a05-a2ad-21d5483f5fed',\n",
              "                        [{\"name\": \"dft_time\", \"type\": \"scatter\", \"x\": [2, 128, 256, 512, 1024], \"y\": [0.0004000663757324219, 0.21411514282226562, 0.8266479969024658, 3.3941431045532227, 14.067471742630005]}, {\"name\": \"fft_time\", \"type\": \"scatter\", \"x\": [2, 128, 256, 512, 1024], \"y\": [0.00018262863159179688, 0.00929403305053711, 0.018061161041259766, 0.036330461502075195, 0.07091903686523438]}],\n",
              "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},\n",
              "                        {\"responsive\": true}\n",
              "                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('edb339e8-8a54-4a05-a2ad-21d5483f5fed');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })\n",
              "                };\n",
              "                \n",
              "            </script>\n",
              "        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQpfjguI1Z3_"
      },
      "source": [
        "# Short-time Fourier Transform (2 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ooYVmiV01Z4A"
      },
      "source": [
        "    Use torch.hann_window"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ablo2kwa1Z4A"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9WtszBl1Z4B"
      },
      "source": [
        "# MelScale (2 pts)\n",
        "\n",
        "[Tap on me](http://practicalcryptography.com/miscellaneous/machine-learning/guide-mel-frequency-cepstral-coefficients-mfccs/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pu0pZxzG1Z4B"
      },
      "source": [
        "# TODO"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jtq5JAaY1Z4C"
      },
      "source": [
        "# Digit classification (5 pts)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gY_JP2EG1Z4C"
      },
      "source": [
        "    1) Download data from google drive: https://drive.google.com/file/d/1ouSOru91p-ZJCyI6E8cGh7N0r3vffi06/view?usp=sharing\n",
        "    \n",
        "    2) Split data in 80/20 proportion. Please note that both the train and the test\n",
        "    must contain all types of digits and all speakers, so carefully split the data.\n",
        "    \n",
        "    3) The AudioMNIST dataset1 consists of 30000 audio recordings (9.5 hours) \n",
        "    of spoken digits (0-9) in English with 50 repetitions per digit for each of the 60 different speakers.\n",
        "    \n",
        "    4) Build a classificator of spoken digits. You can use any neural network architecture you like.\n",
        "        The minimum required quality of classificator will be announced.\n",
        "    \n",
        "    5) Each wavfile has the following format: digit_speackerid_wavid.wav\n",
        "        For example, 6_01_47.wav:\n",
        "            6 -- the number 6 is spoken\n",
        "            01 -- the number is spoken by 1 speaker\n",
        "            47 -- id of wavfile        \n",
        "\n",
        "    Bonus:\n",
        "        If you implement a good model or use some augmentation (or something else),\n",
        "        you can expect to obtain bonuses of up to 3 points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nog20ZT1Z4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}